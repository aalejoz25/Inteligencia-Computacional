{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "Tarea Perceptrón - Redes Neuronales Artificiales\n",
    " Clasificación de pureza de petróleo usando algoritmo supervisado de Hebb\n",
    "\n",
    "* _Maria Alejandra Bonilla Diaz - 20251595002_ \n",
    "* _Alvaro Alejandro Zarabanda Gutierrez – 20251595006_\n",
    "* _Youssef Alejandro Ortiz Vargas – 20251595004_\n",
    "\n",
    "A partir del análisis de un proceso de destilación de petróleo se observó que determinado producto podría ser clasificado en dos clases de pureza (C1 y C2), mediante la medición de tres variables (x₁, x₂, x₃) que representan algunas de las propiedades fisicoquímicas del petróleo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "Datos de entrenamiento\n",
    "Conjunto de datos del Anexo con 30 muestras de entrenamiento con 3 características cada una."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Muestras de entrenamiento: 30\n",
      "Variables de entrada: 3\n",
      "Clases: [-1.  1.]\n",
      "\n",
      "Primeras 5 muestras:\n",
      "x1\t\tx2\t\tx3\t\tClase\n",
      "-0.6508\t\t0.1097\t\t4.0009\t\t-1\n",
      "-1.4492\t\t0.8896\t\t4.4005\t\t-1\n",
      "2.0850\t\t0.6876\t\t12.0710\t\t-1\n",
      "0.2626\t\t1.1476\t\t7.7985\t\t1\n",
      "0.6418\t\t1.0234\t\t7.0427\t\t1\n"
     ]
    }
   ],
   "source": [
    "# Conjunto de entrenamiento del Anexo\n",
    "datos_entrenamiento = np.array([\n",
    "    [-0.6508, 0.1097, 4.0009, -1.0000],\n",
    "    [-1.4492, 0.8896, 4.4005, -1.0000],\n",
    "    [2.0850, 0.6876, 12.0710, -1.0000],\n",
    "    [0.2626, 1.1476, 7.7985, 1.0000],\n",
    "    [0.6418, 1.0234, 7.0427, 1.0000],\n",
    "    [0.2569, 0.6730, 8.3265, -1.0000],\n",
    "    [1.1155, 0.6043, 7.4446, 1.0000],\n",
    "    [0.0914, 0.3399, 7.0677, -1.0000],\n",
    "    [0.0121, 0.5256, 4.6316, 1.0000],\n",
    "    [-0.0429, 0.4660, 5.4323, 1.0000],\n",
    "    [0.4340, 0.6870, 8.2287, -1.0000],\n",
    "    [0.2735, 1.0287, 7.1934, 1.0000],\n",
    "    [0.4839, 0.4851, 7.4850, -1.0000],\n",
    "    [0.4089, -0.1267, 5.5019, -1.0000],\n",
    "    [1.4391, 0.1614, 8.5843, -1.0000],\n",
    "    [-0.9115, -0.1973, 2.1962, -1.0000],\n",
    "    [0.3654, 1.0475, 7.4858, 1.0000],\n",
    "    [0.2144, 0.7515, 7.1699, 1.0000],\n",
    "    [0.2013, 1.0014, 6.5489, 1.0000],\n",
    "    [0.6483, 0.2183, 5.8991, 1.0000],\n",
    "    [-0.1147, 0.2242, 7.2435, -1.0000],\n",
    "    [-0.7970, 0.8795, 3.8762, 1.0000],\n",
    "    [-1.0625, 0.6366, 2.4707, 1.0000],\n",
    "    [0.5307, 0.1285, 5.6883, 1.0000],\n",
    "    [-1.2200, 0.7777, 1.7252, 1.0000],\n",
    "    [0.3957, 0.1076, 5.6623, -1.0000],\n",
    "    [-0.1013, 0.5989, 7.1812, -1.0000],\n",
    "    [2.4482, 0.9455, 11.2095, 1.0000],\n",
    "    [2.0149, 0.6192, 10.9263, -1.0000],\n",
    "    [0.2012, 0.2611, 5.4631, 1.0000]\n",
    "])\n",
    "\n",
    "# Separar características y etiquetas\n",
    "X_train = datos_entrenamiento[:, :3]  # Primeras 3 columnas: x1, x2, x3\n",
    "y_train = datos_entrenamiento[:, 3]   # Última columna: clase (1 o -1)\n",
    "\n",
    "print(f\"Muestras de entrenamiento: {len(X_train)}\")\n",
    "print(f\"Variables de entrada: {X_train.shape[1]}\")\n",
    "print(f\"Clases: {np.unique(y_train)}\")\n",
    "\n",
    "# Mostrar primeras 5 muestras\n",
    "print(\"\\nPrimeras 5 muestras:\")\n",
    "print(\"x1\\t\\tx2\\t\\tx3\\t\\tClase\")\n",
    "for i in range(5):\n",
    "    print(f\"{X_train[i,0]:.4f}\\t\\t{X_train[i,1]:.4f}\\t\\t{X_train[i,2]:.4f}\\t\\t{int(y_train[i])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "Implementación del Perceptrón con algoritmo supervisado de Hebb\n",
    "\n",
    "El algoritmo supervisado de Hebb actualiza los pesos según la regla:\n",
    "**w(n+1) = w(n) + α * (d - y) * x**\n",
    "\n",
    "Donde:\n",
    "- α = tasa de aprendizaje (0.01)\n",
    "- d = salida deseada\n",
    "- y = salida actual del perceptrón\n",
    "- x = vector de entrada (incluyendo bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerceptronClasificador:\n",
    "    def __init__(self, factor_aprendizaje=0.01, seed_valor=None):\n",
    "        self.factor_aprendizaje = factor_aprendizaje\n",
    "        self.vector_pesos = None\n",
    "        self.pesos_origen = None\n",
    "        self.iteraciones_totales = 0\n",
    "        self.seed_valor = seed_valor\n",
    "        self.bitacora_aprendizaje = []\n",
    "        self.ha_convergido = False\n",
    "    \n",
    "    def funcion_signo(self, valor_entrada):\n",
    "        \"\"\"Función de activación signo bipolar: retorna 1 si x >= 0, caso contrario -1\"\"\"\n",
    "        return np.where(valor_entrada >= 0, 1, -1)\n",
    "    \n",
    "    def proceso_entrenamiento(self, caracteristicas_X, etiquetas_y, max_iteraciones=5000, mostrar_progreso=False):\n",
    "        \"\"\"\n",
    "        Ejecuta el entrenamiento del perceptrón empleando la regla de Hebb supervisada\n",
    "        Regla de actualización: pesos_nuevos = pesos_antiguos + α * error * entrada\n",
    "        \"\"\"\n",
    "        # Configuración de semilla aleatoria si es proporcionada\n",
    "        if self.seed_valor is not None:\n",
    "            np.random.seed(self.seed_valor)\n",
    "        \n",
    "        total_muestras, total_atributos = caracteristicas_X.shape\n",
    "        \n",
    "        # Añadir término bias (x0 = -1) como primera columna\n",
    "        X_expandido = np.c_[-np.ones((total_muestras, 1)), caracteristicas_X]\n",
    "        \n",
    "        # Inicialización aleatoria de pesos en rango [0, 1]\n",
    "        self.vector_pesos = np.random.random(total_atributos + 1)\n",
    "        self.pesos_origen = self.vector_pesos.copy()\n",
    "        \n",
    "        if mostrar_progreso:\n",
    "            print(f\"Configuración inicial de pesos: {self.vector_pesos}\")\n",
    "        \n",
    "        # Ciclo de entrenamiento por iteraciones\n",
    "        for iteracion_actual in range(max_iteraciones):\n",
    "            errores_acumulados = 0\n",
    "            registro_errores = []\n",
    "            \n",
    "            for idx_muestra in range(total_muestras):\n",
    "                # Computar suma ponderada (net input)\n",
    "                suma_ponderada = np.dot(X_expandido[idx_muestra], self.vector_pesos)\n",
    "                \n",
    "                # Aplicar función de activación\n",
    "                salida_predicha = self.funcion_signo(suma_ponderada)\n",
    "                \n",
    "                # Calcular discrepancia\n",
    "                discrepancia = etiquetas_y[idx_muestra] - salida_predicha\n",
    "                registro_errores.append(abs(discrepancia))\n",
    "                \n",
    "                # Actualizar pesos según regla de Hebb supervisada\n",
    "                if discrepancia != 0:\n",
    "                    self.vector_pesos += self.factor_aprendizaje * discrepancia * X_expandido[idx_muestra]\n",
    "                    errores_acumulados += abs(discrepancia)\n",
    "            \n",
    "            # Registrar estadísticas de la iteración\n",
    "            exactitud_iteracion = 1 - (errores_acumulados / (2 * total_muestras))\n",
    "            self.bitacora_aprendizaje.append({\n",
    "                'iteracion': iteracion_actual + 1,\n",
    "                'errores_totales': errores_acumulados,\n",
    "                'exactitud': exactitud_iteracion,\n",
    "                'pesos_estado': self.vector_pesos.copy()\n",
    "            })\n",
    "            \n",
    "            if mostrar_progreso and (iteracion_actual + 1) % 20 == 0:\n",
    "                print(f\"Iteración {iteracion_actual + 1}: Errores = {errores_acumulados}, Exactitud = {exactitud_iteracion:.3f}\")\n",
    "            \n",
    "            # Condición de terminación: ausencia de errores\n",
    "            if errores_acumulados == 0:\n",
    "                self.iteraciones_totales = iteracion_actual + 1\n",
    "                self.ha_convergido = True\n",
    "                if mostrar_progreso:\n",
    "                    print(f\"¡Convergencia lograda en iteración {iteracion_actual + 1}!\")\n",
    "                break\n",
    "        else:\n",
    "            self.iteraciones_totales = max_iteraciones\n",
    "            self.ha_convergido = False\n",
    "            if mostrar_progreso:\n",
    "                print(f\"Alerta: Límite de iteraciones alcanzado ({max_iteraciones})\")\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def realizar_prediccion(self, caracteristicas_nuevas):\n",
    "        \"\"\"Generar predicciones para nuevos patrones de entrada\"\"\"\n",
    "        # Incorporar bias\n",
    "        X_expandido_nuevas = np.c_[-np.ones((caracteristicas_nuevas.shape[0], 1)), caracteristicas_nuevas]\n",
    "        suma_ponderada = np.dot(X_expandido_nuevas, self.vector_pesos)\n",
    "        return self.funcion_signo(suma_ponderada)\n",
    "    \n",
    "    def extraer_pesos_iniciales(self):\n",
    "        \"\"\"Obtiene pesos iniciales en formato de diccionario estructurado\"\"\"\n",
    "        return {\n",
    "            'peso_bias': self.pesos_origen[0],\n",
    "            'peso_x1': self.pesos_origen[1], \n",
    "            'peso_x2': self.pesos_origen[2],\n",
    "            'peso_x3': self.pesos_origen[3]\n",
    "        }\n",
    "    \n",
    "    def extraer_pesos_finales(self):\n",
    "        \"\"\"Obtiene pesos finales en formato de diccionario estructurado\"\"\"\n",
    "        return {\n",
    "            'peso_bias': self.vector_pesos[0],\n",
    "            'peso_x1': self.vector_pesos[1],\n",
    "            'peso_x2': self.vector_pesos[2], \n",
    "            'peso_x3': self.vector_pesos[3]\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "# Ejecutar 5 entrenamientos con diferentes inicializaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EJECUCIÓN DE SERIE DE 5 EXPERIMENTOS CON PERCEPTRÓN\n",
      "======================================================================\n",
      "\n",
      "--- EXPERIMENTO E1 ---\n",
      "Configuración inicial de pesos: [0.5488135  0.71518937 0.60276338 0.54488318]\n",
      "Iteración 20: Errores = 18.0, Exactitud = 0.700\n",
      "Iteración 40: Errores = 22.0, Exactitud = 0.633\n",
      "Iteración 60: Errores = 14.0, Exactitud = 0.767\n",
      "Iteración 80: Errores = 14.0, Exactitud = 0.767\n",
      "Iteración 100: Errores = 20.0, Exactitud = 0.667\n",
      "Iteración 120: Errores = 20.0, Exactitud = 0.667\n",
      "Iteración 140: Errores = 10.0, Exactitud = 0.833\n",
      "Iteración 160: Errores = 10.0, Exactitud = 0.833\n",
      "Iteración 180: Errores = 14.0, Exactitud = 0.767\n",
      "Iteración 200: Errores = 6.0, Exactitud = 0.900\n",
      "Iteración 220: Errores = 2.0, Exactitud = 0.967\n",
      "Iteración 240: Errores = 16.0, Exactitud = 0.733\n",
      "Iteración 260: Errores = 12.0, Exactitud = 0.800\n",
      "Iteración 280: Errores = 12.0, Exactitud = 0.800\n",
      "Iteración 300: Errores = 12.0, Exactitud = 0.800\n",
      "Iteración 320: Errores = 16.0, Exactitud = 0.733\n",
      "Iteración 340: Errores = 12.0, Exactitud = 0.800\n",
      "Iteración 360: Errores = 4.0, Exactitud = 0.933\n",
      "Iteración 380: Errores = 12.0, Exactitud = 0.800\n",
      "¡Convergencia lograda en iteración 389!\n",
      "Configuración inicial: bias=0.5488, x1=0.7152, x2=0.6028, x3=0.5449\n",
      "Configuración final:   bias=-3.0312, x1=1.5207, x2=2.4595, x3=-0.7255\n",
      "Iteraciones requeridas: 389\n",
      "\n",
      "--- EXPERIMENTO E2 ---\n",
      "Configuración inicial de pesos: [0.24780909 0.64451682 0.87244454 0.3331428 ]\n",
      "Iteración 20: Errores = 18.0, Exactitud = 0.700\n",
      "Iteración 40: Errores = 18.0, Exactitud = 0.700\n",
      "Iteración 60: Errores = 14.0, Exactitud = 0.767\n",
      "Iteración 80: Errores = 18.0, Exactitud = 0.700\n",
      "Iteración 100: Errores = 14.0, Exactitud = 0.767\n",
      "Iteración 120: Errores = 12.0, Exactitud = 0.800\n",
      "Iteración 140: Errores = 14.0, Exactitud = 0.767\n",
      "Iteración 160: Errores = 10.0, Exactitud = 0.833\n",
      "Iteración 180: Errores = 6.0, Exactitud = 0.900\n",
      "Iteración 200: Errores = 12.0, Exactitud = 0.800\n",
      "Iteración 220: Errores = 12.0, Exactitud = 0.800\n",
      "Iteración 240: Errores = 12.0, Exactitud = 0.800\n",
      "Iteración 260: Errores = 12.0, Exactitud = 0.800\n",
      "Iteración 280: Errores = 6.0, Exactitud = 0.900\n",
      "Iteración 300: Errores = 2.0, Exactitud = 0.967\n",
      "Iteración 320: Errores = 12.0, Exactitud = 0.800\n",
      "Iteración 340: Errores = 0, Exactitud = 1.000\n",
      "¡Convergencia lograda en iteración 340!\n",
      "Configuración inicial: bias=0.2478, x1=0.6445, x2=0.8724, x3=0.3331\n",
      "Configuración final:   bias=-2.9122, x1=1.4346, x2=2.3957, x3=-0.6790\n",
      "Iteraciones requeridas: 340\n",
      "\n",
      "--- EXPERIMENTO E3 ---\n",
      "Configuración inicial de pesos: [0.24611793 0.1147657  0.7727844  0.68787168]\n",
      "Iteración 20: Errores = 20.0, Exactitud = 0.667\n",
      "Iteración 40: Errores = 18.0, Exactitud = 0.700\n",
      "Iteración 60: Errores = 18.0, Exactitud = 0.700\n",
      "Iteración 80: Errores = 14.0, Exactitud = 0.767\n",
      "Iteración 100: Errores = 14.0, Exactitud = 0.767\n",
      "Iteración 120: Errores = 14.0, Exactitud = 0.767\n",
      "Iteración 140: Errores = 12.0, Exactitud = 0.800\n",
      "Iteración 160: Errores = 10.0, Exactitud = 0.833\n",
      "Iteración 180: Errores = 6.0, Exactitud = 0.900\n",
      "Iteración 200: Errores = 6.0, Exactitud = 0.900\n",
      "Iteración 220: Errores = 6.0, Exactitud = 0.900\n",
      "Iteración 240: Errores = 12.0, Exactitud = 0.800\n",
      "Iteración 260: Errores = 12.0, Exactitud = 0.800\n",
      "Iteración 280: Errores = 4.0, Exactitud = 0.933\n",
      "Iteración 300: Errores = 6.0, Exactitud = 0.900\n",
      "Iteración 320: Errores = 6.0, Exactitud = 0.900\n",
      "Iteración 340: Errores = 4.0, Exactitud = 0.933\n",
      "Iteración 360: Errores = 8.0, Exactitud = 0.867\n",
      "Iteración 380: Errores = 4.0, Exactitud = 0.933\n",
      "Iteración 400: Errores = 12.0, Exactitud = 0.800\n",
      "Iteración 420: Errores = 10.0, Exactitud = 0.833\n",
      "Iteración 440: Errores = 0, Exactitud = 1.000\n",
      "¡Convergencia lograda en iteración 440!\n",
      "Configuración inicial: bias=0.2461, x1=0.1148, x2=0.7728, x3=0.6879\n",
      "Configuración final:   bias=-3.1539, x1=1.6037, x2=2.5744, x3=-0.7554\n",
      "Iteraciones requeridas: 440\n",
      "\n",
      "--- EXPERIMENTO E4 ---\n",
      "Configuración inicial de pesos: [0.23662799 0.50156557 0.04607647 0.84609767]\n",
      "Iteración 20: Errores = 16.0, Exactitud = 0.733\n",
      "Iteración 120: Errores = 14.0, Exactitud = 0.767\n",
      "Iteración 140: Errores = 12.0, Exactitud = 0.800\n",
      "Iteración 160: Errores = 10.0, Exactitud = 0.833\n",
      "Iteración 180: Errores = 6.0, Exactitud = 0.900\n",
      "Iteración 200: Errores = 6.0, Exactitud = 0.900\n",
      "Iteración 220: Errores = 6.0, Exactitud = 0.900\n",
      "Iteración 240: Errores = 12.0, Exactitud = 0.800\n",
      "Iteración 260: Errores = 12.0, Exactitud = 0.800\n",
      "Iteración 280: Errores = 4.0, Exactitud = 0.933\n",
      "Iteración 300: Errores = 6.0, Exactitud = 0.900\n",
      "Iteración 320: Errores = 6.0, Exactitud = 0.900\n",
      "Iteración 340: Errores = 4.0, Exactitud = 0.933\n",
      "Iteración 360: Errores = 8.0, Exactitud = 0.867\n",
      "Iteración 380: Errores = 4.0, Exactitud = 0.933\n",
      "Iteración 400: Errores = 12.0, Exactitud = 0.800\n",
      "Iteración 420: Errores = 10.0, Exactitud = 0.833\n",
      "Iteración 440: Errores = 0, Exactitud = 1.000\n",
      "¡Convergencia lograda en iteración 440!\n",
      "Configuración inicial: bias=0.2461, x1=0.1148, x2=0.7728, x3=0.6879\n",
      "Configuración final:   bias=-3.1539, x1=1.6037, x2=2.5744, x3=-0.7554\n",
      "Iteraciones requeridas: 440\n",
      "\n",
      "--- EXPERIMENTO E4 ---\n",
      "Configuración inicial de pesos: [0.23662799 0.50156557 0.04607647 0.84609767]\n",
      "Iteración 20: Errores = 16.0, Exactitud = 0.733\n",
      "Iteración 40: Errores = 18.0, Exactitud = 0.700\n",
      "Iteración 60: Errores = 14.0, Exactitud = 0.767\n",
      "Iteración 80: Errores = 14.0, Exactitud = 0.767\n",
      "Iteración 100: Errores = 16.0, Exactitud = 0.733\n",
      "Iteración 120: Errores = 16.0, Exactitud = 0.733\n",
      "Iteración 140: Errores = 10.0, Exactitud = 0.833\n",
      "Iteración 160: Errores = 10.0, Exactitud = 0.833\n",
      "Iteración 180: Errores = 14.0, Exactitud = 0.767\n",
      "Iteración 200: Errores = 10.0, Exactitud = 0.833\n",
      "Iteración 220: Errores = 12.0, Exactitud = 0.800\n",
      "Iteración 240: Errores = 12.0, Exactitud = 0.800\n",
      "Iteración 260: Errores = 6.0, Exactitud = 0.900\n",
      "Iteración 280: Errores = 12.0, Exactitud = 0.800\n",
      "Iteración 300: Errores = 4.0, Exactitud = 0.933\n",
      "Iteración 320: Errores = 4.0, Exactitud = 0.933\n",
      "Iteración 340: Errores = 4.0, Exactitud = 0.933\n",
      "¡Convergencia lograda en iteración 357!\n",
      "Configuración inicial: bias=0.2366, x1=0.5016, x2=0.0461, x3=0.8461\n",
      "Configuración final:   bias=-2.9834, x1=1.4616, x2=2.4393, x3=-0.7145\n",
      "Iteraciones requeridas: 357\n",
      "\n",
      "--- EXPERIMENTO E5 ---\n",
      "Configuración inicial de pesos: [0.99557752 0.08719167 0.38904648 0.63798315]\n",
      "Iteración 20: Errores = 32.0, Exactitud = 0.467\n",
      "Iteración 40: Errores = 22.0, Exactitud = 0.633\n",
      "Iteración 60: Errores = 18.0, Exactitud = 0.700\n",
      "Iteración 80: Errores = 14.0, Exactitud = 0.767\n",
      "Iteración 100: Errores = 16.0, Exactitud = 0.733\n",
      "Iteración 120: Errores = 16.0, Exactitud = 0.733\n",
      "Iteración 140: Errores = 14.0, Exactitud = 0.767\n",
      "Iteración 160: Errores = 14.0, Exactitud = 0.767\n",
      "Iteración 180: Errores = 10.0, Exactitud = 0.833\n",
      "Iteración 200: Errores = 6.0, Exactitud = 0.900\n",
      "Iteración 220: Errores = 8.0, Exactitud = 0.867\n",
      "Iteración 240: Errores = 6.0, Exactitud = 0.900\n",
      "Iteración 260: Errores = 12.0, Exactitud = 0.800\n",
      "Iteración 280: Errores = 12.0, Exactitud = 0.800\n",
      "Iteración 300: Errores = 12.0, Exactitud = 0.800\n",
      "Iteración 320: Errores = 12.0, Exactitud = 0.800\n",
      "Iteración 340: Errores = 12.0, Exactitud = 0.800\n",
      "Iteración 360: Errores = 4.0, Exactitud = 0.933\n",
      "Iteración 380: Errores = 12.0, Exactitud = 0.800\n",
      "Iteración 400: Errores = 6.0, Exactitud = 0.900\n",
      "Iteración 420: Errores = 4.0, Exactitud = 0.933\n",
      "Iteración 440: Errores = 0, Exactitud = 1.000\n",
      "¡Convergencia lograda en iteración 440!\n",
      "Configuración inicial: bias=0.9956, x1=0.0872, x2=0.3890, x3=0.6380\n",
      "Configuración final:   bias=-3.1044, x1=1.5736, x2=2.4833, x3=-0.7392\n",
      "Iteraciones requeridas: 440\n",
      "\n",
      "======================================================================\n",
      "FINALIZACIÓN DE TODOS LOS EXPERIMENTOS\n",
      "Iteración 40: Errores = 18.0, Exactitud = 0.700\n",
      "Iteración 60: Errores = 14.0, Exactitud = 0.767\n",
      "Iteración 80: Errores = 14.0, Exactitud = 0.767\n",
      "Iteración 100: Errores = 16.0, Exactitud = 0.733\n",
      "Iteración 120: Errores = 16.0, Exactitud = 0.733\n",
      "Iteración 140: Errores = 10.0, Exactitud = 0.833\n",
      "Iteración 160: Errores = 10.0, Exactitud = 0.833\n",
      "Iteración 180: Errores = 14.0, Exactitud = 0.767\n",
      "Iteración 200: Errores = 10.0, Exactitud = 0.833\n",
      "Iteración 220: Errores = 12.0, Exactitud = 0.800\n",
      "Iteración 240: Errores = 12.0, Exactitud = 0.800\n",
      "Iteración 260: Errores = 6.0, Exactitud = 0.900\n",
      "Iteración 280: Errores = 12.0, Exactitud = 0.800\n",
      "Iteración 300: Errores = 4.0, Exactitud = 0.933\n",
      "Iteración 320: Errores = 4.0, Exactitud = 0.933\n",
      "Iteración 340: Errores = 4.0, Exactitud = 0.933\n",
      "¡Convergencia lograda en iteración 357!\n",
      "Configuración inicial: bias=0.2366, x1=0.5016, x2=0.0461, x3=0.8461\n",
      "Configuración final:   bias=-2.9834, x1=1.4616, x2=2.4393, x3=-0.7145\n",
      "Iteraciones requeridas: 357\n",
      "\n",
      "--- EXPERIMENTO E5 ---\n",
      "Configuración inicial de pesos: [0.99557752 0.08719167 0.38904648 0.63798315]\n",
      "Iteración 20: Errores = 32.0, Exactitud = 0.467\n",
      "Iteración 40: Errores = 22.0, Exactitud = 0.633\n",
      "Iteración 60: Errores = 18.0, Exactitud = 0.700\n",
      "Iteración 80: Errores = 14.0, Exactitud = 0.767\n",
      "Iteración 100: Errores = 16.0, Exactitud = 0.733\n",
      "Iteración 120: Errores = 16.0, Exactitud = 0.733\n",
      "Iteración 140: Errores = 14.0, Exactitud = 0.767\n",
      "Iteración 160: Errores = 14.0, Exactitud = 0.767\n",
      "Iteración 180: Errores = 10.0, Exactitud = 0.833\n",
      "Iteración 200: Errores = 6.0, Exactitud = 0.900\n",
      "Iteración 220: Errores = 8.0, Exactitud = 0.867\n",
      "Iteración 240: Errores = 6.0, Exactitud = 0.900\n",
      "Iteración 260: Errores = 12.0, Exactitud = 0.800\n",
      "Iteración 280: Errores = 12.0, Exactitud = 0.800\n",
      "Iteración 300: Errores = 12.0, Exactitud = 0.800\n",
      "Iteración 320: Errores = 12.0, Exactitud = 0.800\n",
      "Iteración 340: Errores = 12.0, Exactitud = 0.800\n",
      "Iteración 360: Errores = 4.0, Exactitud = 0.933\n",
      "Iteración 380: Errores = 12.0, Exactitud = 0.800\n",
      "Iteración 400: Errores = 6.0, Exactitud = 0.900\n",
      "Iteración 420: Errores = 4.0, Exactitud = 0.933\n",
      "Iteración 440: Errores = 0, Exactitud = 1.000\n",
      "¡Convergencia lograda en iteración 440!\n",
      "Configuración inicial: bias=0.9956, x1=0.0872, x2=0.3890, x3=0.6380\n",
      "Configuración final:   bias=-3.1044, x1=1.5736, x2=2.4833, x3=-0.7392\n",
      "Iteraciones requeridas: 440\n",
      "\n",
      "======================================================================\n",
      "FINALIZACIÓN DE TODOS LOS EXPERIMENTOS\n"
     ]
    }
   ],
   "source": [
    "# Ejecutar serie de 5 entrenamientos con configuraciones aleatorias distintas\n",
    "registro_experimentos = []\n",
    "conjunto_clasificadores = []\n",
    "\n",
    "print(\"EJECUCIÓN DE SERIE DE 5 EXPERIMENTOS CON PERCEPTRÓN\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for num_experimento in range(5):\n",
    "    print(f\"\\n--- EXPERIMENTO E{num_experimento+1} ---\")\n",
    "    \n",
    "    # Instanciar clasificador con semilla única para cada experimento\n",
    "    clasificador_actual = PerceptronClasificador(factor_aprendizaje=0.01, seed_valor=num_experimento*202204206)\n",
    "    \n",
    "    # Ejecutar proceso de entrenamiento\n",
    "    clasificador_actual.proceso_entrenamiento(X_train, y_train, max_iteraciones=1000, mostrar_progreso=True)\n",
    "    \n",
    "    # Almacenar clasificador entrenado\n",
    "    conjunto_clasificadores.append(clasificador_actual)\n",
    "    \n",
    "    # Compilar información del experimento\n",
    "    info_experimento = {\n",
    "        'Experimento': f\"E{num_experimento+1}\",\n",
    "        'peso_bias_inicial': clasificador_actual.pesos_origen[0],\n",
    "        'peso_x1_inicial': clasificador_actual.pesos_origen[1],\n",
    "        'peso_x2_inicial': clasificador_actual.pesos_origen[2],\n",
    "        'peso_x3_inicial': clasificador_actual.pesos_origen[3],\n",
    "        'peso_bias_final': clasificador_actual.vector_pesos[0],\n",
    "        'peso_x1_final': clasificador_actual.vector_pesos[1],\n",
    "        'peso_x2_final': clasificador_actual.vector_pesos[2],\n",
    "        'peso_x3_final': clasificador_actual.vector_pesos[3],\n",
    "        'Iteraciones': clasificador_actual.iteraciones_totales\n",
    "    }\n",
    "    \n",
    "    registro_experimentos.append(info_experimento)\n",
    "    \n",
    "    print(f\"Configuración inicial: bias={clasificador_actual.pesos_origen[0]:.4f}, x1={clasificador_actual.pesos_origen[1]:.4f}, x2={clasificador_actual.pesos_origen[2]:.4f}, x3={clasificador_actual.pesos_origen[3]:.4f}\")\n",
    "    print(f\"Configuración final:   bias={clasificador_actual.vector_pesos[0]:.4f}, x1={clasificador_actual.vector_pesos[1]:.4f}, x2={clasificador_actual.vector_pesos[2]:.4f}, x3={clasificador_actual.vector_pesos[3]:.4f}\")\n",
    "    print(f\"Iteraciones requeridas: {clasificador_actual.iteraciones_totales}\")\n",
    "\n",
    "print(f\"\\n{'=' * 70}\")\n",
    "print(\"FINALIZACIÓN DE TODOS LOS EXPERIMENTOS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "# Tabla de resultados del entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MATRIZ DE RESULTADOS EXPERIMENTALES\n",
      "==================================================================================================================================\n",
      "+---------------+----------------+--------------+--------------+--------------+--------------+------------+------------+------------+---------------+\n",
      "| Experimento   |   bias inicial |   x₁ inicial |   x₂ inicial |   x₃ inicial |   bias final |   x₁ final |   x₂ final |   x₃ final |   Iteraciones |\n",
      "+===============+================+==============+==============+==============+==============+============+============+============+===============+\n",
      "| E1            |         0.5488 |       0.7152 |       0.6028 |       0.5449 |      -3.0312 |     1.5207 |     2.4595 |    -0.7255 |           389 |\n",
      "+---------------+----------------+--------------+--------------+--------------+--------------+------------+------------+------------+---------------+\n",
      "| E2            |         0.2478 |       0.6445 |       0.8724 |       0.3331 |      -2.9122 |     1.4346 |     2.3957 |    -0.679  |           340 |\n",
      "+---------------+----------------+--------------+--------------+--------------+--------------+------------+------------+------------+---------------+\n",
      "| E3            |         0.2461 |       0.1148 |       0.7728 |       0.6879 |      -3.1539 |     1.6037 |     2.5744 |    -0.7554 |           440 |\n",
      "+---------------+----------------+--------------+--------------+--------------+--------------+------------+------------+------------+---------------+\n",
      "| E4            |         0.2366 |       0.5016 |       0.0461 |       0.8461 |      -2.9834 |     1.4616 |     2.4393 |    -0.7145 |           357 |\n",
      "+---------------+----------------+--------------+--------------+--------------+--------------+------------+------------+------------+---------------+\n",
      "| E5            |         0.9956 |       0.0872 |       0.389  |       0.638  |      -3.1044 |     1.5736 |     2.4833 |    -0.7392 |           440 |\n",
      "+---------------+----------------+--------------+--------------+--------------+--------------+------------+------------+------------+---------------+\n",
      "Iteraciones mínimas: 340\n",
      "Iteraciones máximas: 440\n",
      "Promedio de iteraciones: 393.2\n"
     ]
    }
   ],
   "source": [
    "# Generar tabla estructurada con resultados experimentales\n",
    "dataframe_experimentos = pd.DataFrame(registro_experimentos)\n",
    "\n",
    "# Formatear datos para presentación tabular\n",
    "matriz_resultados = []\n",
    "for _, fila_datos in dataframe_experimentos.iterrows():\n",
    "    matriz_resultados.append([\n",
    "        fila_datos['Experimento'],\n",
    "        f\"{fila_datos['peso_bias_inicial']:.4f}\", f\"{fila_datos['peso_x1_inicial']:.4f}\", \n",
    "        f\"{fila_datos['peso_x2_inicial']:.4f}\", f\"{fila_datos['peso_x3_inicial']:.4f}\",\n",
    "        f\"{fila_datos['peso_bias_final']:.4f}\", f\"{fila_datos['peso_x1_final']:.4f}\", \n",
    "        f\"{fila_datos['peso_x2_final']:.4f}\", f\"{fila_datos['peso_x3_final']:.4f}\",\n",
    "        fila_datos['Iteraciones']\n",
    "    ])\n",
    "\n",
    "encabezados_tabla = ['Experimento', \n",
    "           'bias inicial', 'x₁ inicial', 'x₂ inicial', 'x₃ inicial',\n",
    "           'bias final', 'x₁ final', 'x₂ final', 'x₃ final',\n",
    "           'Iteraciones']\n",
    "\n",
    "print(\"MATRIZ DE RESULTADOS EXPERIMENTALES\")\n",
    "print(\"=\" * 130)\n",
    "print(tabulate(matriz_resultados, headers=encabezados_tabla, tablefmt='grid'))\n",
    "\n",
    "# Estadísticas descriptivas\n",
    "lista_iteraciones = [exp['Iteraciones'] for exp in registro_experimentos]\n",
    "print(f\"Iteraciones mínimas: {min(lista_iteraciones)}\")\n",
    "print(f\"Iteraciones máximas: {max(lista_iteraciones)}\")\n",
    "print(f\"Promedio de iteraciones: {np.mean(lista_iteraciones):.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "# Clasificación de nuevas muestras\n",
    "\n",
    "Utilizar cada modelo entrenado para clasificar las 10 nuevas muestras de petróleo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PATRONES DE EVALUACIÓN SIN ETIQUETAS:\n",
      "============================================================\n",
      "Patrón 1: x₁=-0.3565, x₂=0.0620, x₃=5.9891\n",
      "Patrón 2: x₁=-0.7842, x₂=1.1267, x₃=5.5912\n",
      "Patrón 3: x₁=0.3012, x₂=0.5611, x₃=5.8234\n",
      "Patrón 4: x₁=0.7757, x₂=1.0648, x₃=8.0677\n",
      "Patrón 5: x₁=0.1570, x₂=0.8028, x₃=6.3040\n",
      "Patrón 6: x₁=-0.7014, x₂=1.0316, x₃=3.6005\n",
      "Patrón 7: x₁=0.3748, x₂=0.1536, x₃=6.1537\n",
      "Patrón 8: x₁=-0.6920, x₂=0.9404, x₃=4.4058\n",
      "Patrón 9: x₁=-1.3970, x₂=0.7141, x₃=4.9263\n",
      "Patrón 10: x₁=-1.8842, x₂=-0.2805, x₃=1.2548\n",
      "\n",
      "Etiquetas E1: [-1  1  1  1  1  1 -1  1 -1 -1]\n",
      "\n",
      "Etiquetas E2: [-1  1  1  1  1  1 -1  1 -1 -1]\n",
      "\n",
      "Etiquetas E3: [-1  1  1  1  1  1 -1  1 -1 -1]\n",
      "\n",
      "Etiquetas E4: [-1  1  1  1  1  1 -1  1 -1 -1]\n",
      "\n",
      "Etiquetas E5: [-1  1  1  1  1  1 -1  1 -1 -1]\n",
      "\n",
      "==========================================================================================\n",
      "RESULTADOS CLASIFICACION DE MUESTRAS\n",
      "==========================================================================================\n",
      "+----------+---------+---------+--------+------+------+------+------+------+\n",
      "|   Patrón |      x₁ |      x₂ |     x₃ |   E1 |   E2 |   E3 |   E4 |   E5 |\n",
      "+==========+=========+=========+========+======+======+======+======+======+\n",
      "|        1 | -0.3565 |  0.062  | 5.9891 |   -1 |   -1 |   -1 |   -1 |   -1 |\n",
      "+----------+---------+---------+--------+------+------+------+------+------+\n",
      "|        2 | -0.7842 |  1.1267 | 5.5912 |    1 |    1 |    1 |    1 |    1 |\n",
      "+----------+---------+---------+--------+------+------+------+------+------+\n",
      "|        3 |  0.3012 |  0.5611 | 5.8234 |    1 |    1 |    1 |    1 |    1 |\n",
      "+----------+---------+---------+--------+------+------+------+------+------+\n",
      "|        4 |  0.7757 |  1.0648 | 8.0677 |    1 |    1 |    1 |    1 |    1 |\n",
      "+----------+---------+---------+--------+------+------+------+------+------+\n",
      "|        5 |  0.157  |  0.8028 | 6.304  |    1 |    1 |    1 |    1 |    1 |\n",
      "+----------+---------+---------+--------+------+------+------+------+------+\n",
      "|        6 | -0.7014 |  1.0316 | 3.6005 |    1 |    1 |    1 |    1 |    1 |\n",
      "+----------+---------+---------+--------+------+------+------+------+------+\n",
      "|        7 |  0.3748 |  0.1536 | 6.1537 |   -1 |   -1 |   -1 |   -1 |   -1 |\n",
      "+----------+---------+---------+--------+------+------+------+------+------+\n",
      "|        8 | -0.692  |  0.9404 | 4.4058 |    1 |    1 |    1 |    1 |    1 |\n",
      "+----------+---------+---------+--------+------+------+------+------+------+\n",
      "|        9 | -1.397  |  0.7141 | 4.9263 |   -1 |   -1 |   -1 |   -1 |   -1 |\n",
      "+----------+---------+---------+--------+------+------+------+------+------+\n",
      "|       10 | -1.8842 | -0.2805 | 1.2548 |   -1 |   -1 |   -1 |   -1 |   -1 |\n",
      "+----------+---------+---------+--------+------+------+------+------+------+\n"
     ]
    }
   ],
   "source": [
    "patrones_evaluacion = np.array([\n",
    "    [-0.3565, 0.0620, 5.9891],\n",
    "    [-0.7842, 1.1267, 5.5912],\n",
    "    [0.3012, 0.5611, 5.8234],\n",
    "    [0.7757, 1.0648, 8.0677],\n",
    "    [0.1570, 0.8028, 6.3040],\n",
    "    [-0.7014, 1.0316, 3.6005],\n",
    "    [0.3748, 0.1536, 6.1537],\n",
    "    [-0.6920, 0.9404, 4.4058],\n",
    "    [-1.3970, 0.7141, 4.9263],\n",
    "    [-1.8842, -0.2805, 1.2548]\n",
    "])\n",
    "\n",
    "print(\"PATRONES DE EVALUACIÓN SIN ETIQUETAS:\")\n",
    "print(\"=\" * 60)\n",
    "for idx_patron, patron in enumerate(patrones_evaluacion):\n",
    "    print(f\"Patrón {idx_patron+1}: x₁={patron[0]:.4f}, x₂={patron[1]:.4f}, x₃={patron[2]:.4f}\")\n",
    "\n",
    "# Aplicar cada clasificador entrenado a los patrones de evaluación\n",
    "conjunto_predicciones = []\n",
    "for idx_clasificador, clasificador in enumerate(conjunto_clasificadores):\n",
    "    etiquetas_predichas = clasificador.realizar_prediccion(patrones_evaluacion)\n",
    "    conjunto_predicciones.append(etiquetas_predichas)\n",
    "    print(f\"\\nEtiquetas E{idx_clasificador+1}: {etiquetas_predichas}\")\n",
    "\n",
    "# Construir matriz de resultados de clasificación\n",
    "matriz_clasificacion = []\n",
    "for idx_patron in range(len(patrones_evaluacion)):\n",
    "    fila_patron = [idx_patron+1]\n",
    "    fila_patron.extend([f\"{patrones_evaluacion[idx_patron, j]:.4f}\" for j in range(3)])\n",
    "    fila_patron.extend([int(conjunto_predicciones[j][idx_patron]) for j in range(5)])\n",
    "    matriz_clasificacion.append(fila_patron)\n",
    "\n",
    "encabezados_clasificacion = ['Patrón', 'x₁', 'x₂', 'x₃', \n",
    "                         'E1', 'E2', 'E3', 'E4', 'E5']\n",
    "\n",
    "print(f\"\\n{'='*90}\")\n",
    "print(\"RESULTADOS CLASIFICACION DE MUESTRAS\")\n",
    "print(\"=\"*90)\n",
    "print(tabulate(matriz_clasificacion, headers=encabezados_clasificacion, tablefmt='grid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "# Análisis de la Variabilidad en el Número de Épocas\n",
    "\n",
    "La diversidad en el número de iteraciones observada en cada experimento se debe a múltiples factores intrínsecos del algoritmo:\n",
    "\n",
    "##  Factores Determinantes\n",
    "\n",
    "### **Configuración Estocástica Inicial**\n",
    "Cada experimento inicia con vectores de pesos generados aleatoriamente en el intervalo $[0,1]$, creando puntos de partida distintos en el espacio de parámetros del clasificador.\n",
    "\n",
    "\n",
    "### **Proximidad a la Solución Óptima**\n",
    "La velocidad de convergencia está directamente relacionada con la distancia euclidiana entre la configuración inicial y cualquier hiperplano separador válido.\n",
    "\n",
    "\n",
    "### **Topología del Espacio de Búsqueda**\n",
    "El algoritmo navega por el espacio de pesos buscando un hiperplano que separe linealmente las clases y la trayectoria específica depende del punto inicial y puede requerir diferentes cantidades de ajustes según la regla de actualización de Hebb\n",
    "\n",
    "### **Dinámicas de Actualización Secuencial**\n",
    "Aunque el orden de presentación de patrones es constante, las actualizaciones de pesos crean estados intermedios únicos que influyen en iteraciones posteriores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "# Principal limitación del Perceptrón\n",
    "\n",
    "Análisis de la limitación fundamental del perceptrón en problemas de clasificación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "is de resultados."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
